### YamlMime:FAQ
metadata:
  title: Azure Monitor FAQ | Microsoft Docs
  description: Answers to frequently asked questions about Azure Monitor.
  services: azure-monitor
  ms.topic: faq
  ms.service: azure-monitor
  ms.custom: ignite-2022
  author: bwren
  ms.author: bwren
  ms.date: 10/24/2022
title: Azure Monitor Frequently Asked Questions
summary: |
  This Microsoft FAQ is a list of commonly asked questions about Azure Monitor.
  

sections:
  - name: Monitoring data
    questions:
      - question: |
          Where does Azure Monitor get its data?
        answer: |
          Azure Monitor collects data from various sources. These sources include logs and metrics from the Azure platform and resources, custom applications, and agents running on virtual machines. Other services such as Microsoft Defender for Cloud and Network Watcher collect data into a Log Analytics workspace so that it can be analyzed with Azure Monitor data. You can also send custom data to Azure Monitor by using the REST API for logs or metrics. See [Sources of monitoring data for Azure Monitor](data-sources.md).
          
      - question: |
          What data does Azure Monitor collect?
        answer: |
          Azure Monitor collects data from various sources into [logs](logs/data-platform-logs.md) or [metrics](essentials/data-platform-metrics.md). Each type of data has its own relative advantages, and each supports a particular set of features in Azure Monitor. There's a single metrics database for each Azure subscription, and you can create multiple Log Analytics workspaces to collect logs depending on your requirements. See [Azure Monitor data platform](data-platform.md).
          
      - question: |
          Is there a maximum amount of data that I can collect in Azure Monitor?
        answer: |
          There's no limit to the amount of metric data you can collect, but this data is stored for a maximum of 93 days. See [Retention of metrics](essentials/data-platform-metrics.md#retention-of-metrics). There's no limit on the amount of log data that you can collect, but the pricing tier you choose for the Log Analytics workspace might affect the limit. See [Pricing details](https://azure.microsoft.com/pricing/details/monitor/).
          
      - question: |
          How do I access data collected by Azure Monitor?
        answer: |
          Insights and solutions provide a custom experience for working with data stored in Azure Monitor. You can work directly with log data by using a log query written in Kusto Query Language (KQL). In the Azure portal, you can write and run queries and interactively analyze data by using Log Analytics. Analyze metrics in the Azure portal with the metrics explorer. See [Analyze log data in Azure Monitor](logs/log-query-overview.md) and [Analyze metrics with Azure Monitor metrics explorer](essentials/analyze-metrics.md).
          
      - question: |
          Why am I seeing duplicate records in Azure Monitor Logs?
        answer: |
          Occasionally, you might notice duplicate records in Azure Monitor Logs. This duplication is typically from one of the following two conditions:
          
          - Components in the pipeline have retries to ensure reliable delivery at the destination. Occasionally, this capability might result in duplicates for a small percentage of telemetry items.
          - If the duplicate records come from a virtual machine, you might have both the Log Analytics agent and Azure Monitor Agent installed. If you still need the Log Analytics agent installed, configure the Log Analytics workspace to no longer collect data that's also being collected by the data collection rule used by Azure Monitor Agent.
  
  - name: Metrics
    questions:
      - question: |
          Why are metrics from the guest OS of my Azure virtual machine not showing up in metrics explorer?
        answer: |
          [Platform metrics](essentials/monitor-azure-resource.md#monitoring-data) are collected automatically for Azure resources. You must perform some configuration, though, to collect metrics from the guest OS of a virtual machine. For a Windows VM, install the diagnostic extension and configure the Azure Monitor sink as described in [Install and configure Azure Diagnostics extension for Windows (WAD)](agents/diagnostics-extension-windows-install.md). For Linux, install the Telegraf agent as described in [Collect custom metrics for a Linux VM with the InfluxData Telegraf agent](essentials/collect-custom-metrics-linux-telegraf.md).

  - name: Prometheus
    questions:
      - question: |
          What's an Azure Monitor workspace? 
        answer: |
          Prometheus metrics collected by managed service for Prometheus are stored in an Azure Monitor workspace. It's essentially a container where Prometheus metrics from various sources are stored. You might have a single Azure Monitor workspace for all of your Prometheus metrics or you might have requirements for multiple workspaces. See [Azure Monitor workspace overview](essentials/azure-monitor-workspace-overview.md?#azure-monitor-workspace-architecture).  
      - question: |
          What's the difference between an Azure Monitor workspace and a Log Analytics workspace?
        answer: |
          An Azure Monitor workspace is a unique environment for data collected by Azure Monitor. Each workspace has its own data repository, configuration, and permissions. Azure Monitor workspaces will eventually contain all metrics collected by Azure Monitor, including native metrics. Currently, the only data hosted by an Azure Monitor workspace is Prometheus metrics. See [Azure Monitor workspace overview](essentials/azure-monitor-workspace-overview.md). 
      - question: |
          How do I retrieve Prometheus metrics? 
        answer: |
          All data is retrieved from an Azure Monitor workspace by using queries that are written in Prometheus Query Language (PromQL). You can write your own queries, use queries from the open source community, and use Grafana dashboards that include PromQL queries. See the [Prometheus project](https://prometheus.io/docs/prometheus/latest/querying/basics/). 
      - question: |
          Can I delete Prometheus metrics from an Azure Monitor workspace?
        answer: |
          Data is removed from the Azure Monitor workspace according to its data retention period, which is 18 months. 
      - question: |
          Can I view my Prometheus metrics in Azure Monitor metrics explorer? 
        answer: |
          Metrics explorer in Azure Monitor doesn't currently support visualizing Prometheus metric data. Consider using [Azure Managed Grafana](../managed-grafana/index.yml) to visualize your Prometheus metrics. 
      - question: |
          Can I use Azure Managed Grafana in a different region than my Azure Monitor workspace and managed service for Prometheus?
        answer: |
          Yes. When you use managed service for Prometheus, you can create your Azure Monitor workspace in any of the supported regions. Your Azure Kubernetes Service clusters can be in any region and send data into an Azure Monitor workspace in a different region. Azure Managed Grafana can also be in a different region than where you created your Azure Monitor workspace. 
      - question: |
          When I use managed service for Prometheus, can I store data for more than one cluster in an Azure Monitor workspace?
        answer: |
          Yes. Managed service for Prometheus is intended to enable scenarios where you can store data from several Azure Kubernetes Service clusters in a single Azure Monitor workspace. See [Azure Monitor workspace overview](essentials/azure-monitor-workspace-overview.md?#azure-monitor-workspace-architecture).  
      - question: |
          What types of resources can send Prometheus metrics to managed service for Prometheus?
        answer: |
          Our agent can be used on Azure Kubernetes Service clusters and Azure Arc-enabled Kubernetes clusters. It's installed as a managed add-on for AKS clusters and an extension for Azure Arc-enabled Kubernetes clusters and you can configure it to collect the data you want. You can also configure remote write on Kubernetes clusters running in Azure, another cloud, or on-premises by following our instructions for enabling remote write.

          If you use the Azure portal to enable Prometheus metrics collection and install the AKS add-on or Azure Arc-enabled Kubernetes extension from the Insights page of your cluster, it enables logs collection into Log Analytics and Prometheus metrics collection into managed service for Prometheus.
      - question: |
          Does enabling managed service for Prometheus on my Azure Kubernetes Service cluster also enable Container insights?
        answer: |
          You have options for how you can collect your Prometheus metrics. If you use the Azure portal and enable Prometheus metrics collection and install the Azure Kubernetes Service (AKS) add-on from the Azure Monitor workspace UX, it won't enable Container insights and collection of log data. When you go to the Insights page on your AKS cluster, you're prompted to enable Container insights to collect log data.<br>
          
          If you use the Azure portal and enable Prometheus metrics collection and install the AKS add-on from the Insights page of your AKS cluster, it enables log collection into a Log Analytics workspace. and Prometheus metrics collection into an Azure Monitor workspace. 
      - question: |
          I am missing all or some of my metrics. How can I troubleshoot?
        answer: |
          You can use the troubleshooting guide for ingesting Prometheus metrics from the managed agent [here](essentials/prometheus-metrics-troubleshoot.md).
      - question: |
          Why am I missing metrics that have two labels with the same name but different casing?
        answer: |
          Metrics that have two label names that are the same except for their casing will be treated as having duplicate label names. These time series will be dropped upon ingestion since the two labels are seen as the same. For example, the time series `my_metric{ExampleLabel="label_value_0", examplelabel="label_value_1}` will be dropped due to duplicate labels since `ExampleLabel` and `examplelabel` will be seen as the same label name.
      - question: |
           I see some gaps in metric data, why is this occurring?   
        answer: |
           During node updates you might see a 1 to 2 minute gap in metric data for metrics collected from our cluster level collectors because the node that it runs on is being updated as part of a normal update process. This affects cluster-wide targets such as kube-state-metrics and custom application targets that are specified. This occurs when your cluster is updated manually or via auto-update. This is expected behavior that occurs due to the node it runs on being updated. None of our recommended alert rules are affected by this behavior. 
           
  - name: Alerts
    questions:
      - question: |
          What's an alert in Azure Monitor?
        answer: |
          Alerts proactively notify you when important conditions are found in your monitoring data. They allow you to identify and address issues before the users of your system notice them. There are multiple kinds of alerts:
          
          - **Metric**: Metric value exceeds a threshold.
          - **Log query**: Results of a log query match defined criteria.
          - **Activity log**: Activity log event matches defined criteria.
          - **Web test**: Results of availability test match defined criteria.
          
          See [Overview of alerts in Azure](alerts/alerts-overview.md).
          
      - question: |
          What's an action group?
        answer: |
          An action group is a collection of notifications and actions that can be triggered by an alert. Multiple alerts can use a single action group allowing you to use common sets of notifications and actions. See [Create and manage action groups in the Azure portal](alerts/action-groups.md).
          
      - question: |
          What's an action rule?
        answer: |
          An action rule allows you to modify the behavior of a set of alerts that match a certain criteria. This rule allows you to perform such requirements as disabling alert actions during a maintenance window. You can also apply an action group to a set of alerts rather than applying them directly to the alert rules. See [Action rules](alerts/alerts-action-rules.md).
          
  - name: Visualizations
    questions:
      - question: |
          Why can't I see View Designer?
        answer: |
          View Designer is only available for users assigned with Contributor permissions or higher in the Log Analytics workspace.

  - name: Container insights
  
    questions:
      - question: |
          Why do I see info banner "You do not have the right cluster permissions which will restrict your access to Container Insights features. Please reach out to your cluster admin to get the right permission"?
        answer: |
          Container Insights has historically allowed users to access the Azure portal experience based on the access permission of the Log Analytics workspace. It now checks cluster-level permission to provide access to the Azure portal experience. You might need your cluster admin to assign this permission.

          For basic read-only cluster level access, assign the **Monitoring Reader** role for the following types of clusters.

          - AKS without Kubernetes role-based access control (RBAC) authorization enabled
          - AKS enabled with Microsoft Entra SAML-based single sign-on
          - AKS enabled with Kubernetes RBAC authorization
          - AKS configured with the cluster role binding clusterMonitoringUser
          - [Azure Arc-enabled Kubernetes clusters](https://learn.microsoft.com/azure/azure-arc/kubernetes/overview)

          See [Assign role permissions to a user or group](../aks/control-kubeconfig-access.md#assign-role-permissions-to-a-user-or-group) for details on how to assign these roles for AKS and [Access and identity options for Azure Kubernetes Service (AKS)](../aks/concepts-identity.md) to learn more about role assignments.
      - question: |
          What does "Other processes" represent under the Node view?
        answer: |
          *Other processes* are intended to help you clearly understand the root cause of the high resource usage on your node. This information helps you to distinguish usage between containerized processes versus noncontainerized processes.
          
          What are these other processes?
          
          They're noncontainerized processes that run on your node.
          
          How do we calculate this?
          
          **Other processes** = *Total usage from CAdvisor* - *Usage from containerized process*
          
          The other processes include:
          
          - Self-managed or managed Kubernetes noncontainerized processes.
          - Container run-time processes.
          - Kubelet.
          - System processes running on your node.
          - Other non-Kubernetes workloads running on node hardware or a VM.
          
      - question: |
          Why don't I see Image and Name property values populated when I query the ContainerLog table?
        answer: |
          For agent version ciprod12042019 and later, by default these two properties aren't populated for every log line to minimize cost incurred on log data collected. There are two options to query the table that include these properties with their values:
          
          ### Option 1
          
          Join other tables to include these property values in the results.
          
          Modify your queries to include `Image` and `ImageTag` properties from the `ContainerInventory` table by joining on `ContainerID` property. You can include the `Name` property (as it previously appeared in the `ContainerLog` table) from the `KubepodInventory` table's `ContainerName` field by joining on the `ContainerID` property. We recommend this option.
          
          The following example is a sample detailed query that explains how to get these field values with joins.
          
          ```
          //Let's say we're querying an hour's worth of logs
          let startTime = ago(1h);
          let endTime = now();
          //Below gets the latest Image & ImageTag for every containerID, during the time window
          let ContainerInv = ContainerInventory | where TimeGenerated >= startTime and TimeGenerated < endTime | summarize arg_max(TimeGenerated, *)  by ContainerID, Image, ImageTag | project-away TimeGenerated | project ContainerID1=ContainerID, Image1=Image ,ImageTag1=ImageTag;
          //Below gets the latest Name for every containerID, during the time window
          let KubePodInv  = KubePodInventory | where ContainerID != "" | where TimeGenerated >= startTime | where TimeGenerated < endTime | summarize arg_max(TimeGenerated, *)  by ContainerID2 = ContainerID, Name1=ContainerName | project ContainerID2 , Name1;
          //Now join the above 2 to get a 'jointed table' that has name, image & imagetag. Outer left is safer in case there are no kubepod records or if they're latent
          let ContainerData = ContainerInv | join kind=leftouter (KubePodInv) on $left.ContainerID1 == $right.ContainerID2;
          //Now join ContainerLog table with the 'jointed table' above and project-away redundant fields/columns and rename columns that were rewritten
          //Outer left is safer so you don't lose logs even if we can't find container metadata for loglines (due to latency, time skew between data types, etc.)
          ContainerLog
          | where TimeGenerated >= startTime and TimeGenerated < endTime
          | join kind= leftouter (
            ContainerData
          ) on $left.ContainerID == $right.ContainerID2 | project-away ContainerID1, ContainerID2, Name, Image, ImageTag | project-rename Name = Name1, Image=Image1, ImageTag=ImageTag1
          ```
          
          ### Option 2
          
          Reenable collection for these properties for every container log line.
          
          If the first option isn't convenient because of query changes involved, you can reenable collecting these fields. Enable the setting `log_collection_settings.enrich_container_logs` in the agent config map as described in the [data collection configuration settings](containers/container-insights-agent-config.md).
          
          > [!NOTE]
          > We don't recommend the second option for large clusters that have more than 50 nodes. It generates API server calls from every node in the cluster to perform this enrichment. This option also increases data size for every log line collected.
          
      - question: |
          Can I view metrics collected in Grafana?
        answer: |
          Container insights support viewing metrics stored in your Log Analytics workspace in Grafana dashboards. We've provided a template that you can download from the Grafana [dashboard repository](https://grafana.com/grafana/dashboards?dataSource=grafana-azure-monitor-datasource&category=docker). Use it to get started and as a reference to help you learn how to query data from your monitored clusters to visualize in custom Grafana dashboards.

      - question: |
          Why don't I see data in my Log Analytics workspace?
        answer: |
          If you're unable to see any data in the Log Analytics workspace at a certain time every day, you might have reached the default 500-MB limit or the cap specified to control the amount of data to collect daily. When the limit is met for the day, data collection stops and resumes only on the next day. To review your data usage and update to a different pricing tier based on your anticipated usage patterns, see [Azure Monitor Logs pricing information](logs/cost-logs.md).
          
      - question: |
          What are the container states specified in the ContainerInventory table?
        answer: |
          The `ContainerInventory` table contains information about both stopped and running containers. The table is populated by a workflow inside the agent that queries the docker for all the running and stopped containers. The agent forwards that data to the Log Analytics workspace.

      - question: |
          How do I resolve the "Missing Subscription registration" error?
        answer: |
          If you receive the error "Missing Subscription registration for Microsoft.OperationsManagement," you can resolve it by registering the resource provider **Microsoft.OperationsManagement** in the subscription where the workspace is defined. For the steps, see [Resolve errors for resource provider registration](../azure-resource-manager/templates/error-register-resource-provider.md).
          
      - question: |
          Is there support for Kubernetes RBAC-enabled Azure Kubernetes Service clusters?
        answer: |
          The Container Monitoring solution doesn't support Kubernetes role-based access control (RBAC), but it's supported with Container insights. The solution details page might not show the right information in the panes that show data for these clusters.

      - question: |
          How do I enable log collection for containers in the kube-system namespace through Helm?
        answer: |
          The log collection from containers in the kube-system namespace is disabled by default. You can enable log collection by setting an environment variable on Azure Monitor Agent. See the [Container insights](https://aka.ms/azuremonitor-containers-helm-chart) GitHub page.
          
      - question: |
          How do I update Azure Monitor Agent in Container insights to the latest released version?
        answer: |
          To learn how to upgrade the agent, see [Agent management](containers/container-insights-manage-agent.md).
          
      - question: |
          Why are log lines larger than 16 KB split into multiple records in Log Analytics?
        answer: |
          The agent uses the [Docker JSON file logging driver](https://docs.docker.com/config/containers/logging/json-file/) to capture the stdout and stderr of containers. This logging driver splits log lines [larger than 16 KB](https://github.com/moby/moby/pull/22982) into multiple lines when they're copied from stdout or stderr to a file.
          
      - question: |
          How do I enable multi-line logging?
        answer: |
          Container insights now supports multi-line logging (preview), for more information on how to enable, checkout the [Multi-line logging in Container Insights](/azure/azure-monitor/containers/container-insights-logging-v2) docs. 
          
          As an alternative you can also configure all the services to write in JSON format, and then Docker/Moby writes them as a single line. For example, you can wrap your log as a JSON object as shown in the following example for a sample Node.js application
          
          ```
          console.log(json.stringify({ 
                "Hello": "This example has multiple lines:",
                "Docker/Moby": "will not break this into multiple lines",
                "and you'll receive":"all of them in log analytics",
                "as one": "log entry"
                }));
          ```
          
          This data will look like the following example in Azure Monitor for logs when you query for it:
          
          ```
          LogEntry : ({"Hello": "This example has multiple lines:","Docker/Moby": "will not break this into multiple lines", "and you'll receive":"all of them in log analytics", "as one": "log entry"}
          ```
          
          For a detailed look at the issue, see this [GitHub page](https://github.com/moby/moby/issues/22920).
          
      - question: |
          How do I resolve Microsoft Entra errors when I enable live logs?
        answer: |
          You might see the following error: "The reply url specified in the request doesn't match the reply urls configured for the application: '<application ID\>'." For the solution, see [View container data in real time with Container insights](containers/container-insights-livedata-setup.md#configure-azure-ad-integrated-authentication).
          
      - question: |
          Why can't I upgrade a cluster after onboarding?
        answer: |
          Here's the scenario: You enabled Container insights for an Azure Kubernetes Service cluster. Then you deleted the Log Analytics workspace where the cluster was sending its data. Now when you attempt to upgrade the cluster, it fails. To work around this issue, you must disable monitoring and then reenable it by referencing a different valid workspace in your subscription. When you try to perform the cluster upgrade again, it should process and complete successfully.

      - question: |
          Which ports and domains do I need to open or allow for the agent?
        answer: |
          See the [Network firewall requirements](containers/container-insights-onboard.md#network-firewall-requirements) for the proxy and firewall configuration information that's required for the containerized agent with Azure, Azure US Government, and Microsoft Azure operated by 21Vianet clouds.
          
      - question: |
          Is there support for collecting Kubernetes audit logs for ARO clusters?
        answer:
          No. Container insights don't support collection of Kubernetes audit logs.

      - question: |
          Why don't I see Normal event types when I query the KubeEvents table?
        answer:
          By default, Normal event types aren't collected unless the *collect_all_kube_events* ConfigMap setting is enabled. If you need to collect Normal events, enable *collect_all_kube_events setting* in the *container-azm-ms-agentconfig* ConfigMap. See [Configure agent data collection for Container insights](containers/container-insights-agent-config.md) for information on how to configure the ConfigMap.

      - question: |
          Does Container Insights support pod sandboxing?
        answer: |
          Yes, Container Insights supports pod sandboxing through support for Kata Containers. For more details on pod sandboxing in AKS, [refer to the AKS docs](/azure/aks/use-pod-sandboxing).
          
  - name: SQL Insights (preview)
    questions:
      - question: |
          What versions of SQL Server are supported?
        answer: |
          We support SQL Server 2012 and all newer versions. See [Supported versions](/azure/azure-sql/database/sql-insights-overview#supported-versions).
          
      - question: |
          What SQL resource types are supported?
        answer: |
          - Azure SQL Database
          - Azure SQL Managed Instance
          - SQL Server on Azure Virtual Machines (SQL Server running on virtual machines registered with the [SQL virtual machine](/azure/azure-sql/virtual-machines/windows/sql-agent-extension-manually-register-single-vm) provider)
          - Azure Virtual Machines (SQL Server running on virtual machines not registered with the [SQL virtual machine](/azure/azure-sql/virtual-machines/windows/sql-agent-extension-manually-register-single-vm) provider)
          
          See [Supported versions](/azure/azure-sql/database/sql-insights-overview#supported-versions) for more information and for details about scenarios with no support or limited support.
          
      - question: |
          What operating systems for the virtual machine running SQL Server are supported?
        answer: |
          We support all operating systems specified by the [Windows](/azure/azure-sql/virtual-machines/windows/sql-server-on-azure-vm-iaas-what-is-overview#getting-started) and [Linux](/azure/azure-sql/virtual-machines/linux/sql-server-on-linux-vm-what-is-iaas-overview#create) documentation for SQL Server on Azure Virtual Machines.
          
      - question: |
          What operating systems for the monitoring virtual machine are supported?
        answer: |
          Ubuntu 18.04 is currently the only operating system supported for the monitoring virtual machine.

      - question: |
          Where is the monitoring data stored in Log Analytics?
        answer: |
          All the monitoring data is stored in the `InsightsMetrics` table. The `Origin` column has the value `solutions.azm.ms/telegraf/SqlInsights`. The `Namespace` column has values that start with `sqlserver_`.

      - question: |
          How often is data collected?
        answer: |
          The frequency of data collection is customizable. See [Data collected by SQL Insights (preview)](/azure/azure-sql/database/sql-insights-overview#collected-data) for information on the default frequencies. See [Create SQL monitoring profile](/azure/azure-sql/database/sql-insights-enable#create-sql-monitoring-profile) for instructions on customizing frequencies.
          
